{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"pUPIgcFzubYC"},"outputs":[],"source":["# imports\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"AXHV2MNIEk9z"},"source":["# 7.4 解決策：パージされたk-分割交差検証法"]},{"cell_type":"markdown","source":["### スニペット7.1 訓練データセットの観測データのパージング"],"metadata":{"id":"sTP3dEOzvMF0"}},{"cell_type":"code","source":["def getTrainTimes(t1, testTimes):\n","  '''\n","  testTimesを所与として、訓練データの時点を探す\n","  -t1.index:観測データが開始した時点\n","  -t1.vakue:観測データが終了した時点\n","  -testTimes:テストデータの時点\n","  '''\n","\n","  trn = t1.copy(deep=True)\n","  for i,j in testTimes.iteritems()\n","    # テストデータセットのなかで開始する訓練データ\n","    df0=trn[(i<=trn.index)&(trn.index<=j)].index\n","    # テストデータセットのなかで終了する訓練データ\n","    df1=trn[(i<=trn)&(trn<=j)].index\n","    # テストデータセットを覆う訓練データ\n","    df2=trn[(trn.index<=i)&(j<=trn)].index\n","    trn=trn.drop(df0.union(df1).union(df2))\n","  return trn"],"metadata":{"id":"NsWc3bhDuxXy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### スニペット7.2 訓練データのエンバーゴ"],"metadata":{"id":"EgQc3HZywcMQ"}},{"cell_type":"code","source":["def getEmbargoTimes(times, pctEmbargo):\n","  # 各データのエンバーゴ時点を取得\n","  step=int(times.shape[0]*pctEmbargo)\n","  if step==0:\n","    mbrg=pd.Series(times[step:],index=times[:-step])\n","    mbrg=mbrg.append(pd.Series(times[-1], index=times[-step:]))\n","  return mbrg\n","\n","#-----------------------------------------------------------------\n","# パージング前のエンバーゴを含める\n","# testTimes=pd.Series(mbrg[dt1], index=[dt0])\n","# trainTimes=getTrainTimes(t1, testTimes)\n","# testTimes=t1.loc[dt0:dt1].index\n"],"metadata":{"id":"OBWj62D0wfmY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### スニペット7.3 観測データが重複するときの交差検証クラス"],"metadata":{"id":"bSUO4nSJx6cl"}},{"cell_type":"code","source":["class PurgedKFold(_BaseKFold):\n","  '''\n","  区間にまたがるラベルに対して機能するようにkFoldクラスを拡張する\n","  訓練データのうちテストラベル区間と重複する観測値がパージされる\n","  テストデータセットは連続的(shuffle=False)で、間に訓練データがないとする\n","  '''\n","\n","  def __init__(self, n_splits=3, t1=None, pctEmbargo=0.):\n","    if not isinstance(t1, pd.Series):\n","      raise ValueError('Label Through Dates must be a pd.Series')\n","    super(PurgedKFold, self).__init__(n_splits,shuffle=False,random_state=None)\n","    self.t1=t1\n","    self.pctEmbargo=pctEmbargo\n","\n","  def split(self,X,y=None,groups=None):\n","    if (X.index==self.t1.index).sum()!=len(self.t1):\n","      raise ValueError('X and ThruDateValues must have the same index')\n","    indices=np.arange(X.shape[0])\n","    mbrg=int(X.shape[0]*self.pctEmbargo)\n","    test_starts=[(i[0],i[-1]+1) for i in np.array_split(np.arange(X.shape[0]),self.n_splits)]\n","    for i,j in test_starts:\n","      t0=self.t1.index[i] #テストデータセットの始まり\n","      test_indices=indices[i:j]\n","      maxT1Idx=self.t1.index.searchsorted(self.t1[test_indices].max())\n","      train_indices=self.t1.index.searchsorted(self.t1[self.t1<=t0].index)\n","      train_indices=np.concatenate((train_indices, indices[maxT1Idx+mbrg:]))\n","    yield train_indices, test_indices"],"metadata":{"id":"Qm_QpQRwx51X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7.5 sklearnの交差検証法のバグ"],"metadata":{"id":"aLby-5Wr08KS"}},{"cell_type":"markdown","source":["## スニペット7.4 Purged K-Foldクラスの使用"],"metadata":{"id":"g9zxOU2L05x8"}},{"cell_type":"code","source":["def cvScore(clf,X,y,sample_weight,scoring='neg_log_loss',t1=None,cv=None,cvGen=None,pctEmbargo=None):\n","  if scoring not in ['neg_log_loss', 'accuracy']:\n","    raise Exception('wrong scoring method.')\n","  from sklearn.metrics import log_loss, accuracy_score\n","  # from clfSequential import PurgedKFold\n","\n","  if cvGen is None:\n","    #パージ\n","    cvGen=PurgedKFold(n_splits=cv,t1=t1,pctEmbargo=pctEmbargo)\n","  score=[]\n","  for train,test in cvGen.split(X = X):\n","    fit = clf.fit(X = X.iloc[train, : ], y = y.iloc[train], sample_weight = sample_weight.iloc[train].values)\n","    if scoring == 'neg_log_loss':\n","      prob = fit.predict_proba(X.iloc[test, : ])\n","      score_ = -1 * log_loss(y.iloc[test], prob, sample_weight = sample_weight.iloc[test].values, labels = clf.classes_)\n","    else:\n","      pred = fit.predict(X.iloc[test, : ])\n","      score_ = accuracy_score(y.iloc[test], pred, sample_weight = sample_weight.iloc[test].values)\n","    score.append(score_)\n","  return np.array(score)"],"metadata":{"id":"RDk1ho131D-P"},"execution_count":null,"outputs":[]}]}